

# EXP 5: COMPARATIVE ANALYSIS OF DIFFERENT TYPES OF PROMPTING PATTERNS AND EXPLAIN WITH VARIOUS TEST SCENARIOS
# Date:25/09/2025
# Reg no: 212223240031
# Aim: 
To test and compare how different pattern models respond to various prompts (broad or unstructured) versus basic prompts (clearer and more refined) across multiple scenarios.  Analyze the quality, accuracy, and depth of the generated responses 

# AI Tools Required: 
ChatGPT (or any AI tool with prompting capability)

# Explanation: 
### Prompt Types
Naïve Prompt – Broad, unstructured, minimal guidance.

Basic Prompt – Clear, structured, and detailed instructions with context.

### Test Scenarios

We use 4 scenarios:

Creative Story Generation

Answering a Factual Question

Summarizing a Concept

Giving Advice/Recommendations



<img width="385" height="131" alt="image" src="https://github.com/user-attachments/assets/fbcd8d50-d69e-4318-9994-99274a38d086" />


# Outputs
| **Scenario**              | **Naïve Prompt**               | **Naïve Output (Sample)**                                                                | **Basic Prompt**                                                                                                                          | **Basic Output (Sample)**                                                                                                         | **Evaluation**                                                     |
| ------------------------- | ------------------------------ | ---------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------ |
| **Creative Story**        | “Write a story about a robot.” | Short, generic story: *“A robot worked in a city and helped people every day.”*          | “Write a 300-word imaginative story about a robot in a futuristic factory, highlighting its emotions and struggles with humans.”          | Long, emotional story with setting, conflict, resolution. Describes robot’s feelings, human interactions, and futuristic context. | **Basic prompt** gives richer, detailed narrative with creativity. |
| **Factual Question**      | “Tell me about IoT.”           | Simple definition: *“IoT means Internet of Things, connecting devices to the internet.”* | “Explain IoT in detail, including its definition, applications in manufacturing, and benefits for predictive maintenance.”                | Detailed explanation: definition, use cases in manufacturing, predictive maintenance, efficiency gains.                           | **Basic prompt** ensures accuracy, relevance, and depth.           |
| **Summarization**         | “Summarize AI.”                | Broad, long explanation mixing history and uses.                                         | “Summarize Artificial Intelligence in about 150 words, covering definition, subfields (ML, NLP, CV), and industrial applications.”        | Concise, structured summary hitting all requested points within word limit.                                                       | **Basic prompt** produces focused, precise output.                 |
| **Advice/Recommendation** | “Give advice for students.”    | Generic advice: *“Study hard, be focused, and don’t give up.”*                           | “Give 5 practical study tips for engineering students preparing for final exams, covering time management, revision, and stress control.” | Actionable tips: make schedules, practice past papers, take breaks, use group study, sleep well.                                  | **Basic prompt** provides useful, structured, practical advice.    |


# Result

The comparative analysis of different prompting patterns was executed successfully. The outputs confirmed that basic prompts consistently improve the quality, accuracy, and depth of responses compared to naïve prompts.
